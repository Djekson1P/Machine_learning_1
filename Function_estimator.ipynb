{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции Оценки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка - показатель качества нахождения приблежения полученных в результате некоторой операции данных\n",
    "в сравнении с данными которые в рамках условной задачи считаются истинными.\n",
    "\n",
    "\n",
    "Точечная оценка - число оцениваемое на основе наблюдений, предположительно наиболее близкое \n",
    "к оцениваемому параметру.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции оценки:\n",
    "    \n",
    "    \n",
    "    - смещение и дисперсия;\n",
    "    \n",
    "    - Дисперсия и Стандартная ошибка;\n",
    "    \n",
    "    - Оценка Максимального Правдоподобия (MLE);\n",
    "    \n",
    "    - Максимальная апостериорная (MAP) оценка.\n",
    "\n",
    "    \n",
    "Функции потерь:\n",
    "    \n",
    "    - Средняя квадратичная ошибка (MSE);\n",
    "    \n",
    "    - Кросс-энтропия (или логарифмическая функция потерь – log loss);\n",
    "    \n",
    "    - Бинарная классификация;\n",
    "    \n",
    "    - Мульти-классовая классификация;\n",
    "    \n",
    "Оптимизаторы:\n",
    "    \n",
    "    - Градиентный Спуск;\n",
    "    \n",
    "    - Адаград;\n",
    "    \n",
    "    - RMSprop;\n",
    "    \n",
    "    - Адам.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смещение измеряет ожидаемое отклонение от истинного значения функции или параметра. \n",
    "\n",
    "Дисперсия, с другой стороны, показывает меру отклонения от ожидаемого значения оценки, \n",
    "которую может вызвать любая конкретная выборка данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дисперсия или стандартная ошибка оценщика показывает меру ожидания того, как оценка,\n",
    "которую мы вычисляем, будет изменяться по мере того, как мы меняем выборки\n",
    "из базового набора данных, генерирующих процесс.\n",
    "\n",
    "Точно так же, как мы хотели бы, чтобы функция оценки имела малое смещение, \n",
    "мы также стремимся, чтобы у нее была относительно низкая дисперсия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка максимального правдоподобия может быть определена \n",
    "как метод оценки параметров (таких как среднее значение или дисперсия) из выборки данных,\n",
    "так что вероятность получения наблюдаемых данных максимальна.\n",
    "\n",
    "\n",
    "\n",
    "У максимального праводобия есть два свойства\n",
    "\n",
    "  - сходимость;\n",
    "    \n",
    "  - эффективность.\n",
    "\n",
    "\n",
    "Сходимость. По мере того, как число обучающих выборок приближается к бесконечности, оценка максимального правдоподобия сходится к истинному значению параметра.\n",
    "\n",
    "Эффективность. Способ измерения того, насколько мы близки к истинному параметру, – это ожидаемая средняя квадратичная ошибка, вычисление квадратичной разницы между оценочными и истинными значениями параметров, где математическое ожидание вычисляется над  обучающими выборками из данных, генерирующих распределение. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка MAP выбирает точку максимальной апостериорной вероятности \n",
    "(или максимальной плотности вероятности в более распространенном случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь MSE широко используется в линейной регрессии в качестве показателя эффективности. \n",
    "Чтобы рассчитать MSE, надо взять разницу между предсказанными значениями и истинными,\n",
    "возвести ее в квадрат и усреднить по всему набору данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-энтропия измеряет расхождение между двумя вероятностными распределениями. \n",
    "Если кросс-энтропия велика, это означает, что разница между двумя распределениями велика, \n",
    "а если кросс-энтропия мала, то распределения похожи друг на друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бинарная классификация  - при двоичной классификации каждая предсказанная вероятность сравнивается \n",
    "с фактическим значением класса (0 или 1), и вычисляется оценка, \n",
    "которая штрафует вероятность на основе расстояния от ожидаемого значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В алгоритме градиентного спуска мы начинаем со случайных параметров модели и вычисляем ошибку \n",
    "для каждой итерации обучения, продолжая обновлять параметры, чтобы приблизиться к минимальным \n",
    "значениям.\n",
    "\n",
    "Пакетный градиентный спуск: использует все обучающие данные для обновления параметров модели в каждой итерации.\n",
    "\n",
    "Мини-пакетный градиентный спуск: вместо использования всех данных, мини-пакетный градиентный спуск делит тренировочный набор на меньший размер, называемый партией, и обозначаемый буквой «b». Таким образом, мини-пакет «b» используется для обновления параметров модели на каждой итерации.\n",
    "\n",
    "Стохастический Градиентный Спуск (SGD): обновляет параметры, используя только один обучающий параметр на каждой итерации. Такой параметр обычно выбирается случайным образом. Стохастический градиентный спуск часто предпочтителен для оптимизации функций затрат, когда есть сотни тысяч обучающих или более параметров, поскольку он будет сходиться быстрее, чем пакетный градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Адаград адаптирует скорость обучения конкретно к индивидуальным особенностям: это означает, что \n",
    "некоторые веса в вашем наборе данных будут отличаться от других. Это работает очень хорошо для \n",
    "разреженных наборов данных, где пропущено много входных значений. Однако, у Адаграда есть одна \n",
    "серьезная проблема: адаптивная скорость обучения со временем становится очень маленькой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop – это специальная версия Adagrad, разработанная профессором Джеффри Хинтоном в его классе\n",
    "нейронных сетей. Вместо того, чтобы вычислять все градиенты, он вычисляет градиенты только в \n",
    "фиксированном окне. RMSprop похож на Adaprop, это еще один оптимизатор, который пытается решить \n",
    "некоторые проблемы, которые Адаград оставляет открытыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Адам означает адаптивную оценку момента и является еще одним способом использования предыдущих \n",
    "градиентов для вычисления текущих градиентов.\n",
    "Адам также использует концепцию импульса, добавляя доли предыдущих градиентов к текущему. \n",
    "Этот оптимизатор получил довольно широкое распространение и практически принят для использования в \n",
    "обучающих нейронных сетях."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
